# -*- coding: utf-8 -*-
"""6140-chess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yvkTF9wFr2zOovTETkz3SUzj4ygDFbbP

# setup
"""

import numpy as np
import chess
import chess.pgn
from sklearn.linear_model import LogisticRegression as lr
from sklearn.metrics import accuracy_score

# from tqdm.notebook import tqdm
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
import torch
from torch import nn, optim, tensor
from matplotlib import pyplot as plt
from typing import Optional, Generator
import pandas as pd
import os
import pickle
import sys
import torch.nn.functional as F


# from google.colab import drive
# drive.mount("/content/drive")
# data_path = "/content/drive/MyDrive/6140-chess/"
# data_path = "/content/drive/MyDrive/chess/"
data_path = "./"
os.listdir(data_path)
# device = "cuda" if torch.cuda.is_available() else "cpu"


def err(*args, **kwargs):
    print(*args, **kwargs, file=sys.stderr)


def save(data, path):
    pickle.dump(data, open(data_path + path, "wb"))


def load(path):
    return pickle.load(open(data_path + path, "rb"))


os.listdir(data_path)

force = False  # False means don't make the file if it already exists


def gen(build, outfile: str, force: bool = force):
    if force or not os.path.exists(data_path + outfile):
        err("building", data_path + outfile)
        out = build()
        save(out, outfile)
    else:
        err(data_path + outfile, "already found")
    return load(outfile)


"""# data stats"""
err("=== data stats ===")


def to_boards(moves: list[chess.Move]) -> Generator:
    white_move: bool = True
    board: chess.Board = chess.Board()
    for move in moves:
        board.push(move)
        board.clear_stack()
        white_move = not white_move
        if white_move:
            yield board.copy()
        else:
            yield board.mirror().copy()


def get_games(pgn_file: str, limit_games: Optional[int] = None) -> Generator:
    count: int = 0
    with open(pgn_file) as pgn:
        while True:
            g = chess.pgn.read_game(pgn)
            if g is None or count == limit_games:
                break
            count += 1
            headers = {
                k: v
                for k, v in g.headers.items()
                if k in ["Result", "WhiteElo", "BlackElo"]
            }
            yield headers, list(g.mainline_moves())


class GameDataset(Dataset):
    # current usage:
    #   1) init from pgn to get lists of boards
    #   2) call transform_all to change boards to <heuristic|onehot|...>
    # done this way because some of the transforms are expensive and want to do
    #   them before running the model instead of as part of __getitem__
    #   maybe there's a more "pythonic" way to do this ?
    # IMPORTANT: because of the above, make sure you do copy.deepcopy
    #   if you want to reuse the untransformed data (i.e. apply a different
    #   transformation)
    # keeping game_results and game_move_count to make iterating by game
    #   simpler without regenerating the dataset
    def __init__(self, pgn_file: str, limit_games: Optional[int] = None):
        self.totensor = False  # hack to deal with tensor and non-tensor data
        self.xs = []
        self.ys = []
        self.game_headers = []
        for headers, moves in tqdm(get_games(pgn_file, limit_games)):
            boards = []
            # try:
            boards = list(to_boards(moves))
            # except:  # illegal moves occur in some games
            #     print("bad game")
            #     continue
            headers["MoveCount"] = len(boards)
            self.game_headers.append(headers)
            self.xs += boards
            result = headers["Result"]
            if result == "1/2-1/2":
                self.ys += [2] * len(boards)
            else:
                w = result == "1-0"
                for it in boards:
                    self.ys.append(1 if w else 0)
                    w = not w
        self.xs = np.array(self.xs)

    def __len__(self) -> int:
        return len(self.xs)

    def __getitem__(self, i):
        x = self.xs[i]
        y = self.ys[i]
        if self.totensor:
            return tensor(x).to(torch.float32), tensor(y).to(torch.long)
        return x, y

    def with_headers(self) -> Generator:
        idx = 0
        for i, h in enumerate(self.game_headers):
            white = True
            r = h["Result"]
            n = h["MoveCount"]
            for j in range(n):
                x, y = self[idx]
                idx += 1
                yield {
                    "game": i,
                    "result": r,
                    "move_count": n,
                    "move": j,
                    "player": "white" if white else "black",
                    "x": x,
                    "y": y,
                }
                white = not white

    def transform_all(self, transform) -> None:
        # transform(self.cs) # should work since cs is a numpy array
        self.xs = np.array(
            [transform(x) for x in tqdm(self.xs, transform.__name__)]
        )


data_keys = ["train", "validation", "test"]
data = {
    it: gen(lambda: GameDataset(f"{data_path}{it}.pgn", 1000), f"pkl/{it}.pkl")
    for it in data_keys
}


def result_stats(games: GameDataset):
    results = [it["Result"] for it in games.game_headers]
    labels = ["1-0", "0-1", "1/2-1/2"]
    counts = [results.count(it) for it in labels]
    return counts, labels


fig, axs = plt.subplots(1, 3)
for i, d in enumerate(data_keys):
    counts, labels = result_stats(data[d])
    axs[i].pie(counts, labels=labels, autopct="%1.0f%%")
    axs[i].set_title(d)
fig.suptitle("game results")
plt.subplots_adjust(top=1.3)
plt.savefig(data_path + "fig/game_results.png")
plt.clf()


def turn_stats(games: GameDataset):
    return [it["MoveCount"] for it in games.game_headers]


fig, axs = plt.subplots(1, 3)
for i, d in enumerate(data_keys):
    axs[i].hist(turn_stats(data[d]), bins=30)
    axs[i].set_xlabel("game length")
    axs[i].set_ylabel("game count")
    axs[i].set_title(d)
fig.suptitle("game lengths")
fig.tight_layout()
# plt.subplots_adjust(top=1.3)
plt.savefig(data_path + "fig/game_lengths.png")
plt.clf()

"""# generating data"""
err("=== generating data ===")


def board_to_heuristics(board: chess.Board):
    def count(ss: chess.SquareSet) -> int:
        return sum(bool(x) for x in ss.tolist())

    def piece_counts():
        return list(
            count(board.pieces(piece, True)) for piece in chess.PIECE_TYPES
        )

    def material():
        values = {
            chess.PAWN: 1,
            chess.BISHOP: 3,
            chess.KNIGHT: 3,
            chess.BISHOP: 3,
            chess.ROOK: 4,
            chess.QUEEN: 9,
            chess.KING: 0,
        }
        return sum(
            values[piece] * count(board.pieces(piece, True))
            for piece in chess.PIECE_TYPES
        )

    def threats():
        return sum(
            count(board.attackers(True, s))
            for s in chess.SQUARES
            if not board.color_at(s)
        )

    def mobility():
        return len(list(board.legal_moves))

    def center_influence():
        center = [
            8 * 3 + 3,
            8 * 3 + 4,
            8 * 4 + 3,
            8 * 4 + 4,
        ]  # center 4 squares
        return sum(count(board.attackers(True, s)) for s in center)

    def passed_pawns():
        obstruction = [0] * 8
        for i in range(2, 7):  # farthest opposing pawn in each column
            for j in range(8):
                if board.piece_at(i * 8 + j) == "p":
                    obstruction[j] = i
        for j in range(
            1, 7
        ):  # opposing pawns in adjacent columns also obstruct
            obstruction[j - 1] = max(obstruction[j - 1], obstruction[j])
            obstruction[8 - j] = max(obstruction[8 - j], obstruction[j])
        ret = 0
        for i in range(1, 6):
            for j in range(8):
                if board.piece_at(i * 8 + j) == "P" and obstruction[j] < i:
                    ret += 1
        return ret

    def player():
        return [
            material(),
            threats(),
            mobility(),
            center_influence(),
            passed_pawns(),
            *piece_counts(),
        ]

    a = player()
    board = board.mirror()
    b = player()
    return np.array(a + b)


def board_to_onehot(board: chess.Board):
    ret = np.array([], dtype=bool)
    for color in chess.COLORS:
        for piece in chess.PIECE_TYPES:
            ret = np.append(ret, board.pieces(piece, color).tolist())
    return ret


def board_to_2d_onehot(board: np.array):
    return board.reshape((2 * len(chess.PIECE_TYPES), 8, 8))


def encode(name: str, encode):
    data = load(f"pkl/{name}.pkl")
    data.transform_all(encode)
    return data


data_h = {
    it: gen(lambda: encode(it, board_to_heuristics), f"pkl/{it}_h.pkl")
    for it in data_keys
}
data_o = {
    it: gen(lambda: encode(it, board_to_onehot), f"pkl/{it}_o.pkl")
    for it in data_keys
}
data_2do = {
    it: gen(lambda: encode(it + "_o", board_to_2d_onehot), f"pkl/{it}_2do.pkl")
    for it in data_keys
}

# save(GameDataset(drive_path + "train.pgn", 10000), "large.pkl")

# modify values in file
# hack I used because I wanted to change the class in the pkl file without
# remaking all the data
# for d in data_keys:
#     for suf in ["", "_h", "_o"]:
#         name = f"{d}{suf}.pkl"
#         data = load(name)
#         data.totensor = False
#         data._make_slices()
#         save(data, name)

"""# regression model"""
err("=== regression model ===")


def data_xy(boards: GameDataset) -> tuple[list, list[int]]:
    boards.totensor = False
    return zip(*list(boards))


def accuracy(model, boards: GameDataset):
    x, y = data_xy(boards)
    return accuracy_score(y, model.predict(x))


def regression(train):
    train_x, train_y = data_xy(train)
    return lr(max_iter=5000).fit(train_x, train_y)


model_o = gen(lambda: regression(data_o["train"]), "pkl/model_o.pkl")
model_h = gen(lambda: regression(data_h["train"]), "pkl/model_h.pkl")

"""# neural net"""
err("=== neural net ===")


class FeedForward(nn.Module):
    def __init__(
        self,
        input_layer: int,
        hidden_layers: list[int],
        output_layer: int,
        activation=nn.ReLU(),
    ):
        super().__init__()
        self.flatten = nn.Flatten()
        layers = []
        for s in hidden_layers:
            layers.append(nn.Linear(input_layer, s))
            layers.append(activation)
            input_layer = s
        layers.append(nn.Linear(input_layer, output_layer))
        layers.append(nn.Sigmoid())
        self.stack = nn.Sequential(*layers)

    def forward(self, x):
        return self.stack(x)


class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(12, 33, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(33, 16, 2)
        self.fc1 = nn.Linear(16, 120)
        self.fc2 = nn.Linear(120, 84)
        # self.fc3 = nn.Linear(84, 2) win/loss
        self.fc3 = nn.Linear(84, 3)  # win/loss draw

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)  # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size):
        super().__init__()
        self.conv1 = nn.Conv2d(
            in_channels, out_channels, kernel_size, padding=1
        )
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(
            out_channels, out_channels, kernel_size, padding=1
        )
        self.bn2 = nn.BatchNorm2d(out_channels)

        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(
                    in_channels, out_channels, kernel_size=1, bias=False
                ),
                nn.BatchNorm2d(out_channels),
            )
        else:
            self.shortcut = nn.Sequential()

    def forward(self, x):
        identity = x

        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))

        identity = self.shortcut(identity)

        out += identity
        out = F.relu(out)
        return out


class ResNETSimple(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(12, 33, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.res_block1 = ResidualBlock(33, 33, 3)
        self.conv2 = nn.Conv2d(33, 16, 2)
        self.res_block2 = ResidualBlock(16, 16, 3)
        self.fc1 = nn.Linear(16, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 3)  # win/loss draw

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.res_block1(x)
        x = self.pool(F.relu(self.conv2(x)))
        x = self.res_block2(x)
        x = torch.flatten(x, 1)  # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


class BoardValueNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(12, 64, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        self.conv4 = nn.Conv2d(256, 256, 3, padding=1)
        self.bn4 = nn.BatchNorm2d(256)
        self.fc1 = nn.Linear(256 * 2 * 2, 512)  # Updated input size for fc1
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 3)  # win/loss draw

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.pool(F.relu(self.bn4(self.conv4(x))))
        x = torch.flatten(x, 1)  # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


loss_fn = nn.CrossEntropyLoss()


def compute_loss(model, data: DataLoader):  # DataLoader faster than Dataset
    return sum(loss_fn(model(x), y).item() for x, y in data) / len(data)


def train(
    model: nn.Module,
    optimizer,
    train_data: DataLoader,
    validation_data: DataLoader,
) -> Generator:
    while True:
        model.train()
        for x, y in train_data:
            loss = loss_fn(model(x), y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        model.eval()
        yield compute_loss(model, train_data), compute_loss(
            model, validation_data
        )


def ff_train_for(
    model: nn.Module,
    data,
    epochs=50,
    optimizer=optim.SGD,
    lr: float = 0.01,
    bs=64,
):
    opt = optimizer(model.parameters(), lr=lr)
    data[
        "train"
    ].totensor = True  # bit of a hack, sets member variable inside GameDataset
    data["validation"].totensor = True
    train_loader = DataLoader(data["train"], bs, shuffle=True)
    validation_loader = DataLoader(data["validation"], bs)
    trainer = train(model, opt, train_loader, validation_loader)
    losses = [it for it, _ in zip(trainer, tqdm(range(epochs)))]
    return zip(
        *losses
    )  # return columns as separate lists i.e. [train, validation]


# m, t, v = ff_train_o()
# save((m, t, v), "ffmodel_o.pkl")


def ff_train_h():
    model = FeedForward(22, [22, 22], 3)
    train_losses, validation_losses = ff_train_for(model, data_h, 50)
    return (model, train_losses, validation_losses)


def ff_train_o():
    model = FeedForward(768, [768, 768], 3)
    train_losses, validation_losses = ff_train_for(model, data_o, 50)
    return (model, train_losses, validation_losses)


def cnn_train_2do():
    model = CNN()
    train_losses, validation_losses = ff_train_for(model, data_2do, 50)
    return (model, train_losses, validation_losses)


def resscnn_train_2do():
    model = ResNETSimple()
    train_losses, validation_losses = ff_train_for(model, data_2do, 50)
    return (model, train_losses, validation_losses)


def resscnn2_train_2do():
    model = BoardValueNet()
    train_losses, validation_losses = ff_train_for(model, data_2do, 50)
    return (model, train_losses, validation_losses)


ff_model_h, ff_train_losses_h, ff_validation_losses_h = gen(
    lambda: ff_train_h(), "pkl/ffmodel_h.pkl"
)

ff_model_o, ff_train_losses_o, ff_validation_losses_o = gen(
    lambda: ff_train_o(), "pkl/ffmodel_o.pkl"
)

cnn_model_2do, cnn_train_losses_2do, cnn_validation_losses_2do = gen(
    cnn_train_2do, "cnnmodel_2do.pkl"
)

rescnn_model_2do, rescnn_train_losses_2do, rescnn_validation_losses_2do = gen(
    resscnn_train_2do, "rescnnmodel_2do.pkl"
)

(
    rescnn2_model_2do,
    rescnn2_train_losses_2do,
    rescnn2_validation_losses_2do,
) = gen(resscnn2_train_2do, "rescnnmodel2_2do.pkl")


def ff_train_more(path: str, data, **kwargs):
    model, train_losses, validation_losses = load(path)
    t, v = ff_train_for(model, data, **kwargs)
    save((model, train_losses + t, validation_losses + v), path)


# ff_train_more("pkl/ffmodel_h.pkl", data_h)
# ff_train_more("pkl/ffmodel_o.pkl", data_o)

plt.plot(ff_train_losses_h)
plt.plot(ff_validation_losses_h)
plt.xlabel("epoch")
plt.ylabel("loss")
plt.title("heuristics")
plt.savefig(data_path + "fig/ff_h_losses.png")
plt.clf()
# plt.show()

plt.plot(ff_train_losses_o)
plt.plot(ff_validation_losses_o)
plt.xlabel("epoch")
plt.ylabel("loss")
plt.title("onehot")
plt.savefig(data_path + "fig/ff_o_losses.png")
plt.clf()
# plt.show()

plt.plot(cnn_train_losses_2do)
plt.plot(cnn_validation_losses_2do)
plt.xlabel("epoch")
plt.ylabel("loss")
plt.title("onehot CNN 1")
plt.savefig(data_path + "fig/cnn_2do_losses.png")
plt.clf()

# plt.plot(rescnn_train_losses_2do)
# plt.plot(rescnn_validation_losses_2do)
# plt.xlabel("epoch")
# plt.ylabel("loss")
# plt.title("onehot CNN 2")
# plt.savefig(data_path+"fig/rescnn_o_losses.png")
# plt.clf()

# plt.plot(rescnn2_train_losses_2do)
# plt.plot(rescnn2_validation_losses_2do)
# plt.xlabel("epoch")
# plt.ylabel("loss")
# plt.title("onehot CNN 3")
# plt.savefig(data_path+"fig/rescnn2_o_losses.png")
# plt.clf()

"""## predictions"""
err("=== predictions ===")


def tocsv(rows: Generator, path):
    import csv

    first = next(rows)
    # print(first)
    writer = csv.DictWriter(
        open(f"{data_path}{path}", "w"), fieldnames=list(first.keys())
    )
    writer.writeheader()
    writer.writerow(first)
    for it in rows:
        writer.writerow(it)


def predictions(model, data: GameDataset, nn=False) -> Generator:
    data.totensor = nn
    for h in tqdm(data.with_headers()):
        x = h["x"]
        predict = model(x).argmax().item() if nn else model.predict([x]).item()
        h.pop("x")
        if nn:
            h["y"] = h["y"].item()
        h["predict"] = predict
        h["correct"] = predict == h["y"]
        yield h


def predictions_cnn(model, data: GameDataset, nn=False) -> Generator:
    data.totensor = nn
    for h in tqdm(data.with_headers()):
        x = h["x"]
        predict = (
            model(x.unsqueeze(0)).argmax().item()
            if nn
            else model.predict([x]).item()
        )
        h["x"] = None
        if nn:
            h["y"] = h["y"].item()
        h["predict"] = predict
        h["correct"] = predict == h["y"]
        yield h


# print(next(predictions(model_h, data_h["train"])).keys())
# print(next(predictions(ff_model_h, data_h["train"], True)))


def write_predictions(model, data, path, nn=False):
    if os.path.exists(data_path + path):
        err(data_path + path, "already exists")
    else:
        err("generating", data_path + path)
        tocsv(predictions(model, data, nn), data_path + path)


def write_predictions_cnn(model, data, path, nn=False):
    if os.path.exists(data_path + path):
        err(data_path + path, "already exists")
    else:
        err("generating", data_path + path)
        tocsv(predictions_cnn(model, data, nn), data_path + path)


for d in tqdm(data_keys):
    write_predictions(model_h, data_h[d], f"csv/model_h_{d}.csv")
    write_predictions(model_o, data_o[d], f"csv/model_o_{d}.csv")
    write_predictions(ff_model_h, data_h[d], f"csv/ff_model_h_{d}.csv", True)
    write_predictions(ff_model_o, data_o[d], f"csv/ff_model_o_{d}.csv", True)
    write_predictions_cnn(
        cnn_model_2do, data_2do[d], f"csv/cnn_model_2do_{d}.csv", True
    )
    write_predictions_cnn(
        rescnn_model_2do, data_2do[d], f"csv/rescnn_model_2do_{d}.csv", True
    )
    write_predictions_cnn(
        rescnn2_model_2do, data_2do[d], f"csv/rescnn2_model_2do_{d}.csv", True
    )


"""# accuracy"""
err("=== accuracy ===")


def by_class(title: str, *csvfiles):
    def subplot(csvfile):
        df = pd.read_csv(f"{data_path}csv/{csvfile}.csv")
        # select sum(correct) / count(correct) group by y
        grouped_df = df.groupby("y").agg({"correct": ["sum", "count"]})
        grouped_df["correct_ratio"] = (
            grouped_df["correct"]["sum"] / grouped_df["correct"]["count"]
        )
        return grouped_df["correct_ratio"]

    plt.ylabel("Accuracy")
    ind = np.arange(3)  # 3 labels: win,loss,draw
    width = 0.3
    for i, it in enumerate(csvfiles):
        ratios = subplot(it)
        plt.bar(ind + i * width, ratios, width, label=it)
    plt.xticks(ind, ["loss", "win", "draw"])
    plt.grid()
    plt.legend()
    title += " by class"
    plt.title(title)
    plt.savefig(f"{data_path}fig/{title.replace(' ', '_')}.png")
    plt.clf()
    # plt.show()


by_class("heuristic regression", "model_h_train", "model_h_test")
by_class("onehot regression", "model_o_train", "model_o_test")
by_class("heuristic neural net", "ff_model_h_train", "ff_model_h_test")
by_class("onehot neural net", "ff_model_o_train", "ff_model_o_test")
by_class("onehot 2d CNN net", "cnn_model_2do_train", "cnn_model_2do_test")
by_class(
    "onehot 2d Residual Neural Net",
    "rescnn_model_2do_train",
    "rescnn_model_2do_test",
)
by_class(
    "onehot 2d Modified CNN Net",
    "rescnn2_model_2do_train",
    "rescnn2_model_2do_test",
)


def by_turn(title: str, *csvfiles):
    def subplot(csvfile):
        df = pd.read_csv(f"{data_path}csv/{csvfile}.csv")
        # select sum(correct) / count(correct) group by turn
        grouped_df = df.groupby("move").agg({"correct": ["sum", "count"]})[
            :160
        ]
        grouped_df["correct_ratio"] = (
            grouped_df["correct"]["sum"] / grouped_df["correct"]["count"]
        )
        grouped_df.reset_index(inplace=True)
        return plt.plot(
            grouped_df["move"], grouped_df["correct_ratio"], label=csvfile
        )

    plt.xlabel("Move #")
    plt.ylabel("Accuracy")
    plt.title("Accuracy by Move #")
    for it in csvfiles:
        subplot(it)
    plt.grid()
    plt.legend()
    title += " by turn"
    plt.title(title)
    plt.savefig(f"{data_path}fig/{title}.png")
    plt.clf()
    # plt.show()


by_turn("heuristic regression", "model_h_train", "model_h_test")
by_turn("onehot regression", "model_o_train", "model_o_test")
by_turn("heuristic neural net", "ff_model_h_train", "ff_model_h_test")
by_turn("onehot neural net", "ff_model_o_train", "ff_model_o_test")
by_turn("onehot CNN 1 net", "cnn_model_2do_train", "cnn_model_2do_test")
by_turn(
    "onehot Resiual net", "rescnn_model_2do_train", "rescnn_model_2do_test"
)
by_turn(
    "onehot CNN 2 net", "rescnn2_model_2do_train", "rescnn2_model_2do_test"
)


"""# other charts"""
err("=== other charts ===")

# piece heat map
# print(model_o.coef_.shape)
h = model_o.coef_.reshape(3, 12, 8, 8)
for i, l in enumerate(["loss", "win", "draw"]):
    fig, axs = plt.subplots(2, 6)
    for it in range(12):
        # TODO: label rows
        color = "your" if it < 6 else "opponent"
        a = axs[it // 6, it % 6]
        a.set_title(f"{color}\n{chess.PIECE_NAMES[it%6+1]}")
        a.imshow(h[i][it], cmap="hot")
        a.set_axis_off()
    fig.suptitle(l, y=0.85)
    fig.tight_layout()
    fig.subplots_adjust(hspace=-0.5)
    plt.savefig(f"{data_path}fig/{l}_heatmap.png")
    plt.clf()
    # plt.show()


def nn_accuracy(model: nn.Module, data: GameDataset):
    model.eval()
    num_classes = 3
    accuracy = 0
    class_accuracy = np.zeros(num_classes)
    class_count = np.zeros(num_classes)
    data.totensor = True
    for x, y in data:
        actual: int = int(y.item())
        class_count[actual] += 1
        if model(x).argmax().item() == actual:
            accuracy += 1
            class_accuracy[actual] += 1
    return accuracy / len(data), class_accuracy / class_count


def nn_accuracy_cnn(model: nn.Module, data: GameDataset):
    model.eval()
    num_classes = 3
    accuracy = 0
    class_accuracy = np.zeros(num_classes)
    class_count = np.zeros(num_classes)
    data.totensor = True
    for x, y in data:
        actual: int = int(y.item())
        class_count[actual] += 1
        if model(x.unsqueeze(0)).argmax().item() == actual:
            accuracy += 1
            class_accuracy[actual] += 1
    return accuracy / len(data), class_accuracy / class_count


for it in data_keys:
    print(it, nn_accuracy(ff_model_h, data_h[it]))

for it in data_keys:
    print(it, nn_accuracy(ff_model_o, data_o[it]))

for it in data_keys:
    print(it, nn_accuracy_cnn(cnn_model_2do, data_2do[it]))

for it in data_keys:
    print(it, nn_accuracy_cnn(rescnn_model_2do, data_2do[it]))

for it in data_keys:
    print(it, nn_accuracy_cnn(rescnn2_model_2do, data_2do[it]))
